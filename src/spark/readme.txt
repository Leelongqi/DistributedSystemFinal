此处存放spark分布式计算相关代码
 Spark提供一个pySpark的编程接口，可以并行处理计算文件数据。根据本项目要求需要计算三个问题。
	问题一：计算出用户的每日平均通话次数，并将结果以<主叫号码, 每日平均通话次数>的格式保存成 txt 或 excel 文件。
1)	读入数据并使用rdd.map()处理为分布式列表；
2)	使用rdd.map()函数记录所有数据中每个用户1次通话，由于可能每个用户可能通了多次电话，所以使用rdd.reduceByKey()函数记录所有数据中每个不同用户通话次数times；
3)	取出每个用户以及其对应的通话日期，用集合性质进行日期去重处理，然后使用rdd.combineByKey()函数记录每个不同用户以及其对应不同通话日期列表dates。
4)	使用rdd.fullOuterJoin()函数将数据格式变为[‘user’,(times,dates)],计算用户的每日平均通话次数：evert_time=times/dates
5)	使用rdd.collect()函数将RDD所有元素返回一个列表list;
6)	将列表中的每个元素读入到txt文件中，结果以<主叫号码, 每日平均通话次数>的格式保存。
	问题二：计算出不同通话类型（市话1、长途2、国际3）下各个运营商（电信1，移动2，联通3）的占比。
1)	读入数据并使用rdd.map()处理为分布式列表；
2)	使用rdd.map()函数获取通话类型数据与被叫用户；
3)	使用rdd.combineByKey()函数获取在不用通话类型下的各个运营商记录，数据结构为[‘通话类型’，[各个运营商记录]]；
4)	使用rdd.collect()函数将三种通话类型返回为3个List，通话类型市话1下的各个运营商列表记为List1，通话类型长途2下的各个运营商列表记为List2，通话类型国际3下的各个运营商列表记为List3;
5)	使用sc.parallelize()函数将List1处理为分布式列表，然后依次使用rdd.map()、rdd.reduceByKey()函数，处理为统计不同运营商次数，数据结构为[(‘电信1’，次数)]，[(‘移动2’，次数)]，[(‘联通3’，次数)]，使用rdd.collect()函数将rdd中的每个元素形成一个列表。List2,List3处理过程类似；
6)	计算不同通话类型下各个运营商的占比：由第5)中可知，计算在市话通话类型下，电信占比=电信次数/(电信次数+移动次数+联通次数)，移动占比=移动次数/(电信次数+移动次数+联通次数)，联通占比=联通次数/(电信次数+移动次数+联通次数)；在长途与国际通话类型下计算方法一致；
7)	将计算结果存入一个列表中，然后将列表中的每个元素读入到txt文件中。
	问题三：计算出用户在各个时间段（时间段的划分如表 1 所示）通话时长所占比例，并将结果以<主叫号码, 时间段 1 占比, ..., 时间段 8 占比>的格式保存成 txt 或 excel 文件。
1)	读入数据并使用rdd.map()处理为分布式列表；
2)	定义函数1：将每个用户开始通话时间(00：00：00)转换为秒(s)，返回的数据结构为[‘用户’，开始通话时间]，然后用rdd.map()调用这个函数；
3)	定义函数2：计算每个用户在8个时间段的通话时长，返回的数据结构为[‘用户’，8个时间段的通话时长列表]，然后用rdd.map()调用这个函数；
4)	使用rdd.combineByKey()函数获取每个用户不同日期的8个时间段的通话时长列表，数据结构为[‘用户’，列表1，列表2，…，列表n]；
5)	定义函数3：将每个用户的8个时间段的通话时长相加，返回的数据结构为[‘用户’，整合8个时间段的通话时长列表]，然后用rdd.map()调用这个函数，使用rdd.collect()函数将rdd中的每个元素形成一个列表；
6)	计算用户在8个时间段通话时长所占比例；
7)	将计算结果存入一个列表中，然后将列表中的每个元素读入到txt文件中，结果以<主叫号码, 时间段 1 占比, ..., 时间段 8 占比>的格式保存成excel 文件。
